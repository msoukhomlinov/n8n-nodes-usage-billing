# General Rules
- Use Australian English spelling and conventions
- When trying to run commands (Agent or Compose), remember that you are on Windows with PowerShell Core

# MCP Rules
Search the web using Brave web search using the MCP tool first to see what people are saying before fixing anything that could be quite technical.
Use Code and Issue Researcher to assist with the following to enhance insight and learn the latest information/fixes:
Sequential thinking - for all tasks
Puppeteer - web browsing or web scraping
Server memory - for storing and refrerencing key information across moderate to complex work

For code indentation, uou must use spaces instead of tabs
# Instructions

During you interaction with the user, if you find anything reusable in this project (e.g. version of a library, model name), especially about a fix to a mistake you made or a correction you received, you should take note in the `Lessons` section in the `.cursorrules` file so you will not make the same mistake again.

You should also use the `.cursorrules` file as a scratchpad to organize your thoughts. Especially when you receive a new task, you should first review the content of the scratchpad, clear old different task if necessary, first explain the task, and plan the steps you need to take to complete the task. You can use todo markers to indicate the progress, e.g.
[X] Task 1
[ ] Task 2

Also update the progress of the task in the Scratchpad when you finish a subtask.
Especially when you finished a milestone, it will help to improve your depth of task accomplishment to use the scratchpad to reflect and plan.
The goal is to help you maintain a big picture as well as the progress of the task. Always refer to the Scratchpad when you plan the next step.

# Documentation Files
# MCP Server Tools Usage

## Strategic Tool Selection

- **Sequential Thinking:**
  - Use for multi-step operations requiring careful planning.
  - Maintain operational context to enable course correction.
  - Begin with a higher number of total thoughts (e.g. 8â€“12) for complex tasks.
  - Use branching to explore alternative approaches and mark revisions when needed.
  - Set `needsMoreThoughts=true` when new complexities arise.

- **Web Research (via Brave Search):**
  - Always conduct initial broad searches, then follow with detailed research.
  - Validate technical approaches, error handling strategies, and best practices.
  - Cross-reference multiple reputable sources before implementation.

- **Puppeteer Operations:**
  - Use for intricate web interactions and testing.
  - Implement chained operations with robust error handling, waits, and retries.
  - Optimise memory by closing pages when done and reusing browser instances.

- **Server Memory (Knowledge Graph):**
  - Maintain complex relationships and operational context.
  - Create entities for major components and concepts.
  - Map dependencies and document architectural decisions.
  - Regularly clean up obsolete entities and update relationships.

- **Memory (@itseasy21\mcp-knowledge-graph):**
  - Start with "Remembering..." and read what you stored in memory before working on a task
  - Reference knowledge as "memory"
  - When the assigned task is done:
    1. Create/update entities
    2. Define relationships
    3. Store observations

- **Firecrawl MCP:**
  - Use for advanced web crawling and data extraction tasks.
  - Efficiently navigate complex websites and extract structured data.
  - Handle pagination, authentication, and dynamic content loading.
  - Process and transform extracted data for integration with other systems.

### Sequential Thinking
- Use for operations requiring multiple steps
- Essential for maintaining operational context
- Helps break down large changes into manageable chunks
- Enables course correction and revision of approach
- Key usage patterns:
  * Start with higher total_thoughts for complex tasks (8-12)
  * Use branching for exploring alternative approaches
  * Mark revisions when changing previous decisions
  * Set needsMoreThoughts=true when discovering new complexity
  * Use as tactical memory during long operations

### Web Research (Brave Search)
- Always search before implementing complex features
- Research patterns:
  * Start with broad concept search
  * Follow up with specific implementation details
  * Look for recent discussions and solutions
  * Cross-reference multiple sources
  * Use for validating approach before major changes
- Key usage:
  * Technical implementation patterns
  * Error handling strategies
  * Best practices validation
  * Community solutions to similar problems

### Puppeteer Operations
- Use for complex web interactions and testing
- Strategic patterns:
  * Chain operations with proper error handling
  * Use screenshots for validation points
  * Implement waits and retries for stability
  * Maintain session context across operations
- Memory management:
  * Close pages when done
  * Reuse browser instances when possible
  * Clear large objects after operations
  * Monitor memory usage in long sessions

### Memory Management
- Start with "Remembering..." and read what you stored in memory before working on a task
- Reference knowledge as "memory"
- When the assigned task is done:
  1. Create/update entities
  2. Define relationships
  3. Store observations

### Firecrawl Operations
- Use for comprehensive web data extraction
- Strategic patterns:
  * Define clear extraction targets and selectors
  * Handle site navigation and state management
  * Process and transform extracted data
  * Implement error recovery and retry mechanisms
- Best practices:
  * Respect website terms of service and robots.txt
  * Implement rate limiting to avoid overloading servers
  * Store extracted data efficiently
  * Validate data integrity after extraction

## Operational Guidelines

### For Moderate Changes (30-100 lines):
1. Start with sequential thinking (5-8 thoughts)
2. Research similar implementations
3. Plan key validation points
4. Execute with regular state checks

### For Large Changes (100+ lines):
1. Begin with comprehensive sequential thinking (10+ thoughts)
2. Extensive research phase
3. Break into sub-operations
4. Regular validation checkpoints
5. Maintain operational memory through scratchpad

# Lessons
- When working with n8n nodes, be prepared to handle stringified data or incorrect data types
- Objects in arrays can be incorrectly converted to "[object Object]" strings when passed between nodes
- Always add data type validation and conversion for input data in n8n nodes
- Use try/catch blocks when parsing JSON to handle potential errors gracefully
- When expecting arrays, check for single objects and wrap them in arrays if needed
- In n8n nodes that perform lookups/calculations, always include all matched fields and calculation components in the output by default
- Use prefixes (like "usage_" and "price_") to prevent field name collisions in output data
- When debugging n8n nodes, add detailed logging throughout the execution flow to trace data transformations and field matching
- Implement case insensitive matching for string fields to make lookups more resilient to formatting differences
- Handle both string paths and direct data objects from n8n expressions - when users use expressions like {{ $json }}, n8n evaluates them to the actual data, not a path string
- Implement case-insensitive field name lookups for matching operations to handle inconsistent capitalization between data sources
- When outputting data from lookup operations, include only relevant fields (match fields, calculation fields) instead of all fields to keep output clean
- When enhancing n8n nodes with new configuration options, all related files need to be updated: nodeDescription.ts, interface definitions, node implementation, and processing logic
- For n8n nodes, it's important to maintain backward compatibility by making new interface properties optional and providing default values
- When changing field names or keys used in output, consider existing users who might expect the old names/keys
- When adding prefix configuration to output field names, remember to update all occurrences where fields are added to the output
- When implementing match logic, ensure you properly handle cases with multiple matches by returning arrays instead of single items
- Keep console logging minimal and focused in production code - verbose logging makes debugging harder and can impact performance
- When handling n8n expressions, consider all possible data formats that might be passed (arrays, objects, strings, etc.)
- When implementing debugging logs, strike a balance between verbosity and clarity - include identifying information to track individual items being processed
- When handling parameters that accept n8n expressions, implement detection for "direct data mode" vs. "field path mode" to ensure proper processing of each item
- Prefer simple, standardized approaches over special-case handling - make the most common use case the default behavior
- Avoid hardcoding field names in the code - use dynamic approaches to detect field types and handle data structures flexibly

# Scratchpad

## Current Task: Standardize on Direct Data Mode in BillingCalculator
[X] Remove special "direct data mode" detection logic
[X] Make processing each item directly the default behavior
[X] Simplify usage data extraction to only handle string field paths
[X] Rename extractUsageData to extractDataFromFieldPath for clarity
[X] Clean up and streamline console logging
[X] Keep compatibility with both direct data and field path approaches

## Task Summary
Standardized the BillingCalculator node to use direct data mode as the default approach:

1. Removed the special "direct data mode" detection logic
2. Made processing each item directly the default behavior instead of a special case
3. Added explicit handling for string field paths (only when a non-empty string path is provided)
4. Simplified the extractUsageData function and renamed it to extractDataFromFieldPath
5. Streamlined the code by removing special cases and complicated conditional logic
6. Maintained compatibility with both approaches: direct item usage and field path extraction

This refactoring simplifies the node's implementation while making the most common use case (direct item processing) the default behavior, resulting in cleaner, more maintainable code.
